{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849dbd89-ce04-4a18-84fb-c19f3db5504a",
   "metadata": {},
   "source": [
    "# Building optimized RAG with LlamaIndex + DSPy\n",
    "\n",
    "This notebook provides a comprehensive overview of LlamaIndex + DSPy integrations.\n",
    "\n",
    "We show **three** core integrations:\n",
    "1. **Build and optimize Query Pipelines with DSPy predictors**: The first section shows you how to write DSPy code to define signatures for LLM inputs/outputs. Then port over these components to overall workflows within LlamaIndex Query pipelines, and then end-to-end optimize the entire system.\n",
    "\n",
    "2. **Build and optimize Query Pipelines with Existing Prompts**: Instead of writing DSPy signatures, you can just define a LlamaIndex prompt template, and our converter will auto-optimize it for you.\n",
    "\n",
    "3. **Port over DSPy-Optimized Prompts to any LlamaIndex Module**: Possible through our `DSPyPromptTemplate` - translate an optimized prompt through DSPy into any module that requires prompts in LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa558b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78.28s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: llama-index 0.11.6\n",
      "Uninstalling llama-index-0.11.6:\n",
      "  Successfully uninstalled llama-index-0.11.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83.72s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index==0.11.6\n",
      "  Using cached llama_index-0.11.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.3.0)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.3.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.6 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.11.6)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.2.4)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.3.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.2 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.2.2)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.2.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.2.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (0.3.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index==0.11.6) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.0->llama-index==0.11.6) (1.43.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (2.0.33)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (2024.6.1)\n",
      "Requirement already satisfied: httpx in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (3.3)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index==0.11.6) (0.0.17)\n",
      "Requirement already satisfied: pandas in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.6) (2.1.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.6) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.6) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.6) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.6) (0.5.2)\n",
      "Requirement already satisfied: click in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from nltk>3.8.1->llama-index==0.11.6) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from nltk>3.8.1->llama-index==0.11.6) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from nltk>3.8.1->llama-index==0.11.6) (2024.7.24)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.9.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.6) (2.6)\n",
      "Requirement already satisfied: anyio in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (3.8)\n",
      "Requirement already satisfied: sniffio in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index==0.11.6) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index==0.11.6) (0.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.6) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.6) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.6) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.6->llama-index==0.11.6) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/channel/miniconda3/envs/pz/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.6) (1.16.0)\n",
      "Using cached llama_index-0.11.6-py3-none-any.whl (6.8 kB)\n",
      "Installing collected packages: llama-index\n",
      "Successfully installed llama-index-0.11.6\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall llama-index -y\n",
    "!pip install \"llama-index==0.11.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b152a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "assert(len(os.getenv('OPENAI_API_KEY')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d223313-af5b-4155-8896-c24aa4cb6925",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Define the LLM setting for DSPy (note: this is separate from using the LlamaIndex LLMs), and also the answer signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5c50d5e-7046-40c5-bf3e-a8d2a2a2c6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo')\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac68be4f-36b1-4054-99dd-707ce42f61a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context_str = dspy.InputField(desc=\"contains relevant facts\")\n",
    "    query_str = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2a981-2ee1-497a-b675-15e1029183f6",
   "metadata": {},
   "source": [
    "## [Part 1] Build and Optimize a Query Pipeline with DSPy Modules\n",
    "\n",
    "Use our DSPy query components to plugin DSPy prompts/LLMs, stitch together with our query pipeline abstraction.\n",
    "\n",
    "Any query pipeline can be plugged into our `LlamaIndexModule`. We can then let DSPy optimize the entire thing e2e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f0637-993f-4bef-bd8a-1122951cf7f8",
   "metadata": {},
   "source": [
    "#### Load Data, Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c9d434-c8f6-403e-9499-36059eb09907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89.54s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-06 15:10:38--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘paul_graham_essay.txt’\n",
      "\n",
      "paul_graham_essay.t 100%[===================>]  73.28K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-09-06 15:10:39 (2.01 MB/s) - ‘paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# port it over to another index  (paul graham example) \n",
    "\n",
    "!wget https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt -O paul_graham_essay.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "367a7985-2f89-47be-b2af-14fef2e845c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=[\"paul_graham_essay.txt\"])\n",
    "docs = reader.load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9a68920-6517-465b-8c0c-4c6e0b8390a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d43c6c-9dee-4cbc-b39d-5d8ad617b6ea",
   "metadata": {},
   "source": [
    "#### Build Query Pipeline\n",
    "\n",
    "Replace the synthesis piece with the DSPy component (make sure GenerateAnswer matches signature of inputs/outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac7df48b-9369-4f17-8542-0f8afd9e621e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP, InputComponent, FnComponent\n",
    "from dspy.predict.llamaindex import DSPyComponent, LlamaIndexModule\n",
    "\n",
    "dspy_component = DSPyComponent(\n",
    "    dspy.Predict(GenerateAnswer)\n",
    ")\n",
    "\n",
    "retriever_post = FnComponent(\n",
    "    lambda contexts: \"\\n\\n\".join([n.get_content() for n in contexts])\n",
    ")\n",
    "\n",
    "\n",
    "p = QP(verbose=True)\n",
    "p.add_modules(\n",
    "    {\n",
    "        \"input\": InputComponent(),\n",
    "        \"retriever\": retriever,\n",
    "        \"retriever_post\": retriever_post,\n",
    "        \"synthesizer\": dspy_component,\n",
    "    }\n",
    ")\n",
    "p.add_link(\"input\", \"retriever\")\n",
    "p.add_link(\"retriever\", \"retriever_post\")\n",
    "p.add_link(\"input\", \"synthesizer\", dest_key=\"query_str\")\n",
    "p.add_link(\"retriever_post\", \"synthesizer\", dest_key=\"context_str\")\n",
    "\n",
    "\n",
    "dspy_qp = LlamaIndexModule(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b457f1db-3315-476c-8673-bf19ad6e1657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: what did the author do in YC\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retriever with input: \n",
      "input: what did the author do in YC\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retriever_post with input: \n",
      "contexts: [NodeWithScore(node=TextNode(id_='fb626aa5-b633-48b3-8a79-7614ca3ac4a5', embedding=None, metadata={'file_path': 'paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain'...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module synthesizer with input: \n",
      "query_str: what did the author do in YC\n",
      "context_str: YC was different from other kinds of work I've done. Instead of deciding for myself what to work on, the problems came to me. Every 6 months there was a new batch of startups, and their problems, what...\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "output = dspy_qp(query_str=\"what did the author do in YC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b78501f-e281-4e68-bdb6-1eeca6bf2464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Funded startups, helped founders.'\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d5d86-1ce0-46fd-9fbc-eca68043c935",
   "metadata": {},
   "source": [
    "#### Optimize Query Pipeline\n",
    "\n",
    "Let's try optimizing the query pipeline with few-shot examples.\n",
    "\n",
    "We define a toy dataset with two examples. We then use our `SemanticSimilarityEvaluator` to define a custom eval function to pass to the DSPy teleprompter.\n",
    "- Because our passing threshold is set to very low, every example should pass with a reasonable LLM. \n",
    "- What this practically means is that all training examples will be added as few-shot examples to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec3a783c-2025-4b1c-9f5b-cdcde7211ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dspy import Example\n",
    "\n",
    "train_examples = [\n",
    "    Example(query_str=\"What did the author do growing up?\", answer=\"The author wrote short stories and also worked on programming.\"),\n",
    "    Example(query_str=\"What did the author do during his time at YC?\", answer=\"organizing a Summer Founders Program, funding startups, writing essays, working on a new version of Arc, creating Hacker News, and developing internal software for YC\")\n",
    "]\n",
    "\n",
    "train_examples = [t.with_inputs(\"query_str\") for t in train_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e43a18c-5569-4947-a02d-08f52331b134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "502cc403-8ebc-4bbf-be7c-c15385909b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'InputComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'RetrieverComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'RetrieverComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'FnComponent' object has no attribute '__pydantic_fields_set__'\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "its ok 'FnComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'FnComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'FnComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'DSPyComponent' object has no attribute '__pydantic_fields_set__'\n",
      "Unexpected error during deepcopy: SignatureMeta.__new__() missing 3 required positional arguments: 'signature_name', 'bases', and 'namespace'\n",
      "its ok 'DSPyComponent' object has no attribute '__pydantic_fields_set__'\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "its ok 'DSPyComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'InputComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'RetrieverComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'OpenAIEmbedding' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SimpleVectorStore' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'SentenceSplitter' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'RetrieverComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'FnComponent' object has no attribute '__pydantic_fields_set__'\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "its ok 'FnComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'FnComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'FnComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'DSPyComponent' object has no attribute '__pydantic_fields_set__'\n",
      "Unexpected error during deepcopy: SignatureMeta.__new__() missing 3 required positional arguments: 'signature_name', 'bases', and 'namespace'\n",
      "its ok 'DSPyComponent' object has no attribute '__pydantic_fields_set__'\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "Unexpected error during deepcopy: function() missing required argument 'code' (pos 1)\n",
      "its ok 'DSPyComponent' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n",
      "its ok 'QueryPipeline' object has no attribute '__pydantic_fields_set__'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]ERROR:dspy.teleprompt.bootstrap:\u001b[2m2024-09-06T22:10:46.440926Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mFailed to run or to evaluate example Example({'query_str': 'What did the author do growing up?', 'answer': 'The author wrote short stories and also worked on programming.'}) (input_keys={'query_str'}) with <function validate_context_and_answer at 0x7fc438f49300> due to 'QueryPipeline' object has no attribute '__pydantic_fields_set__'.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.teleprompt.bootstrap\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mbootstrap.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m211\u001b[0m\n",
      "ERROR:dspy.teleprompt.bootstrap:\u001b[2m2024-09-06T22:10:46.441891Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mFailed to run or to evaluate example Example({'query_str': 'What did the author do during his time at YC?', 'answer': 'organizing a Summer Founders Program, funding startups, writing essays, working on a new version of Arc, creating Hacker News, and developing internal software for YC'}) (input_keys={'query_str'}) with <function validate_context_and_answer at 0x7fc438f49300> due to 'QueryPipeline' object has no attribute '__pydantic_fields_set__'.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.teleprompt.bootstrap\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mbootstrap.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m211\u001b[0m\n",
      "100%|██████████| 2/2 [00:00<00:00, 628.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from llama_index.core.evaluation import SemanticSimilarityEvaluator\n",
    "\n",
    "evaluator = SemanticSimilarityEvaluator(similarity_threshold=0.5)\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    result = evaluator.evaluate(response=pred.answer, reference=example.answer)\n",
    "    return result.passing\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(max_labeled_demos=0, metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_dspy_qp = teleprompter.compile(dspy_qp, trainset=train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a147c3e-febe-43fa-bca5-152432d3662b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test this out \n",
    "compiled_dspy_qp(query_str=\"How did PG meet Jessica Livingston?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2ba4e-6677-44e7-a474-db382ad1a56a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [optional]: inspect history\n",
    "turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895ceff-5aeb-4285-8ede-99bb35a50a45",
   "metadata": {},
   "source": [
    "## [Part 2] Build and Optimize Query Pipelines with Existing Prompts\n",
    "\n",
    "Build a query pipeline similar to the previous section. But instead of directly using DSPy signatures/predictors, we can build DSPyComponent modules from LlamaIndex prompts directly. \n",
    "\n",
    "This allows you to write any LlamaIndex prompt and trust that it'll be optimized in DSPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efff3a9-77d9-4a89-a0f7-207d63e73ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "# let's try a fun prompt that writes in Shakespeare! \n",
    "qa_prompt_template = PromptTemplate(\"\"\"\\\n",
    "Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, \\\n",
    "answer the query.\n",
    "\n",
    "Write in the style of a Shakespearean sonnet.\n",
    "\n",
    "Query: {query_str}\n",
    "Answer: \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84aa7b2-b9b8-4740-b862-9073470c31c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP, InputComponent, FnComponent\n",
    "from dspy.predict.llamaindex import DSPyComponent, LlamaIndexModule\n",
    "\n",
    "dspy_component = DSPyComponent.from_prompt(qa_prompt_template)\n",
    "\n",
    "retriever_post = FnComponent(\n",
    "    lambda contexts: \"\\n\\n\".join([n.get_content() for n in contexts])\n",
    ")\n",
    "\n",
    "\n",
    "p = QP(verbose=True)\n",
    "p.add_modules(\n",
    "    {\n",
    "        \"input\": InputComponent(),\n",
    "        \"retriever\": retriever,\n",
    "        \"retriever_post\": retriever_post,\n",
    "        \"synthesizer\": dspy_component,\n",
    "    }\n",
    ")\n",
    "p.add_link(\"input\", \"retriever\")\n",
    "p.add_link(\"retriever\", \"retriever_post\")\n",
    "p.add_link(\"input\", \"synthesizer\", dest_key=\"query_str\")\n",
    "p.add_link(\"retriever_post\", \"synthesizer\", dest_key=\"context_str\")\n",
    "\n",
    "\n",
    "dspy_qp = LlamaIndexModule(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb253fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b7662-cb87-4906-bbaf-e2ffd74e20d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the inferred signature\n",
    "dspy_component.predict_module.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044855f-cdd2-43f0-9d2e-e7ba64a28e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from llama_index.core.evaluation import SemanticSimilarityEvaluator\n",
    "from dspy import Example\n",
    "\n",
    "output_key = \"sonnet_answer\"\n",
    "train_example_dicts = [\n",
    "    {\"query_str\": \"What did the author do growing up?\", output_key: \"The author wrote short stories and also worked on programming.\"},\n",
    "    {\"query_str\": \"What did the author do during his time at YC?\", output_key: \"organizing a Summer Founders Program, funding startups, writing essays, working on a new version of Arc, creating Hacker News, and developing internal software for YC\"}\n",
    "]\n",
    "train_examples = [Example(**t).with_inputs(\"query_str\") for t in train_example_dicts]\n",
    "\n",
    "evaluator = SemanticSimilarityEvaluator(similarity_threshold=0.5)\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    result = evaluator.evaluate(response=getattr(pred, output_key), reference=getattr(example, output_key))\n",
    "    return result.passing\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(max_labeled_demos=0, metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_dspy_qp = teleprompter.compile(dspy_qp, trainset=train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcb28c-c442-4f1d-8876-9c6c6c47eda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test this out \n",
    "compiled_dspy_qp(query_str=\"How did PG meet Jessica Livingston?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1b5f7-66d0-49d2-9bae-ca94f12a124d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [optional]: inspect the optimized prompt \n",
    "turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4daae77-bf36-418f-9a80-c9c0fb6f20ec",
   "metadata": {},
   "source": [
    "## [Part 3] Port over Optimized Prompts to LlamaIndex using the DSPy Prompt Template\n",
    "\n",
    "Extract out a prompt from an existing compiled DSPy module, and then port it over to any LlamaIndex pipeline! \n",
    "\n",
    "In the example below we use our `DSPyPromptTemplate` to extract out the compiled few-shot prompt from the optimized query pipeline. \n",
    "\n",
    "We then plug it into a separate query engine over the PG essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180ea2b-412a-41a6-a707-f2945d9dcda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dspy.predict.llamaindex import DSPyPromptTemplate\n",
    "\n",
    "# NOTE: you cannot do DSPyPromptTemplate(dspy_component.predict_module) - the predict_module is replaced.\n",
    "qa_prompt_tmpl = DSPyPromptTemplate(compiled_dspy_qp.query_pipeline.module_dict[\"synthesizer\"].predict_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c86e63-f225-4540-b1a2-a48a13e29756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(qa_prompt_tmpl.format(query_str=\"hello?\", context_str=\"this is my context\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3097d9c-89e3-4d89-ae8d-6a57bd4fda0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    text_qa_template=qa_prompt_tmpl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b8d58-ddb0-468c-854f-bf475134d653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"what did the author do at RISD?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93b21d-2766-404e-833f-5a1cb3bf8891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pz-kernel",
   "language": "python",
   "name": "pz-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
